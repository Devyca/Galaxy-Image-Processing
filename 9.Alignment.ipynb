{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3d4fbd-cc13-42e1-ac0e-647f5e3b0ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking input files...\n",
      "  Found: clear - /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized/normalized_NGC1365_clear_stacked_sigma3.0.fits\n",
      "  Found: g - /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized/normalized_NGC1365_g_stacked_sigma3.0.fits\n",
      "  Found: r - /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized/normalized_NGC1365_r_stacked_sigma3.0.fits\n",
      "  Found: i - /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized/normalized_NGC1365_i_stacked_sigma3.0.fits\n",
      "\n",
      "======================================================================\n",
      "Starting alignment process...\n",
      "Reference filter: r\n",
      "======================================================================\n",
      "\n",
      "Loading reference image: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized/normalized_NGC1365_r_stacked_sigma3.0.fits\n",
      "Reference saved: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/second_alignment/aligned_NGC1365_r_stacked_sigma3.0.fits\n",
      "\n",
      "Processing: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized/normalized_NGC1365_clear_stacked_sigma3.0.fits\n",
      "  Calculating cross-correlation shift...\n",
      "  Detected shift: dy=15.174, dx=-0.026 pixels\n",
      "  Applying subpixel shift...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Card is too long, comment will be truncated. [astropy.io.fits.card]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/second_alignment/aligned_NGC1365_clear_stacked_sigma3.0.fits\n",
      "\n",
      "Processing: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized/normalized_NGC1365_g_stacked_sigma3.0.fits\n",
      "  Calculating cross-correlation shift...\n",
      "  Detected shift: dy=-2.486, dx=-16.461 pixels\n",
      "  Applying subpixel shift...\n",
      "  Saved: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/second_alignment/aligned_NGC1365_g_stacked_sigma3.0.fits\n",
      "\n",
      "Processing: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized/normalized_NGC1365_i_stacked_sigma3.0.fits\n",
      "  Calculating cross-correlation shift...\n",
      "  Detected shift: dy=16.820, dx=14.604 pixels\n",
      "  Applying subpixel shift...\n",
      "  Saved: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/second_alignment/aligned_NGC1365_i_stacked_sigma3.0.fits\n",
      "\n",
      "======================================================================\n",
      "Alignment complete!\n",
      "Aligned images saved to: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/second_alignment\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from scipy import ndimage\n",
    "from scipy.signal import correlate\n",
    "from scipy.ndimage import fourier_shift\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def cross_correlation_shift(reference, target):\n",
    "    \"\"\"\n",
    "    Calculate the shift between reference and target images using cross-correlation.\n",
    "    Returns subpixel shift values (dy, dx).\n",
    "    \"\"\"\n",
    "    # Compute cross-correlation\n",
    "    correlation = correlate(reference, target, mode='same', method='fft')\n",
    "    \n",
    "    # Find the peak of correlation\n",
    "    peak = np.unravel_index(np.argmax(correlation), correlation.shape)\n",
    "    \n",
    "    # Calculate shift (center of image is zero shift)\n",
    "    center = np.array(reference.shape) // 2\n",
    "    shift = np.array(peak) - center\n",
    "    \n",
    "    # Refine to subpixel precision using parabolic interpolation\n",
    "    def subpixel_peak(corr, peak_idx):\n",
    "        \"\"\"Refine peak position to subpixel accuracy\"\"\"\n",
    "        y, x = peak_idx\n",
    "        \n",
    "        # Check boundaries\n",
    "        if y <= 0 or y >= corr.shape[0]-1 or x <= 0 or x >= corr.shape[1]-1:\n",
    "            return peak_idx\n",
    "        \n",
    "        # Parabolic interpolation in y direction\n",
    "        dy = 0\n",
    "        denom_y = 2 * (corr[y-1, x] - 2*corr[y, x] + corr[y+1, x])\n",
    "        if denom_y != 0:\n",
    "            dy = (corr[y-1, x] - corr[y+1, x]) / denom_y\n",
    "        \n",
    "        # Parabolic interpolation in x direction\n",
    "        dx = 0\n",
    "        denom_x = 2 * (corr[y, x-1] - 2*corr[y, x] + corr[y, x+1])\n",
    "        if denom_x != 0:\n",
    "            dx = (corr[y, x-1] - corr[y, x+1]) / denom_x\n",
    "        \n",
    "        return (y + dy, x + dx)\n",
    "    \n",
    "    refined_peak = subpixel_peak(correlation, peak)\n",
    "    refined_shift = np.array(refined_peak) - center\n",
    "    \n",
    "    return refined_shift\n",
    "\n",
    "def apply_shift(image, shift):\n",
    "    \"\"\"\n",
    "    Apply subpixel shift to image using Fourier shift theorem.\n",
    "    shift: (dy, dx) tuple\n",
    "    \"\"\"\n",
    "    # Fourier shift for subpixel precision\n",
    "    shifted = fourier_shift(np.fft.fftn(image), shift)\n",
    "    shifted = np.fft.ifftn(shifted).real\n",
    "    \n",
    "    return shifted\n",
    "\n",
    "def align_images(reference_path, target_paths, output_dir):\n",
    "    \"\"\"\n",
    "    Align multiple images to a reference using cross-correlation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    reference_path : str\n",
    "        Path to reference FITS file\n",
    "    target_paths : list\n",
    "        List of paths to target FITS files to align\n",
    "    output_dir : str\n",
    "        Directory to save aligned images\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load reference image\n",
    "    print(f\"Loading reference image: {reference_path}\")\n",
    "    with fits.open(reference_path) as hdul:\n",
    "        reference_data = hdul[0].data.astype(np.float64)\n",
    "        reference_header = hdul[0].header.copy()\n",
    "    \n",
    "    # Save reference image (no alignment needed)\n",
    "    ref_filename = Path(reference_path).name.replace('normalized', 'aligned')\n",
    "    ref_output_path = os.path.join(output_dir, ref_filename)\n",
    "    fits.writeto(ref_output_path, reference_data, reference_header, overwrite=True)\n",
    "    print(f\"Reference saved: {ref_output_path}\")\n",
    "    print()\n",
    "    \n",
    "    # Process each target image\n",
    "    for target_path in target_paths:\n",
    "        print(f\"Processing: {target_path}\")\n",
    "        \n",
    "        # Load target image\n",
    "        with fits.open(target_path) as hdul:\n",
    "            target_data = hdul[0].data.astype(np.float64)\n",
    "            target_header = hdul[0].header.copy()\n",
    "        \n",
    "        # Calculate shift\n",
    "        print(\"  Calculating cross-correlation shift...\")\n",
    "        shift = cross_correlation_shift(reference_data, target_data)\n",
    "        print(f\"  Detected shift: dy={shift[0]:.3f}, dx={shift[1]:.3f} pixels\")\n",
    "        \n",
    "        # Apply shift\n",
    "        print(\"  Applying subpixel shift...\")\n",
    "        aligned_data = apply_shift(target_data, shift)\n",
    "        \n",
    "        # Update header with alignment info\n",
    "        target_header['ALIGNED'] = (True, 'Image aligned using cross-correlation')\n",
    "        target_header['ALIGNREF'] = (Path(reference_path).name, 'Reference image for alignment')\n",
    "        target_header['SHIFT_Y'] = (float(shift[0]), 'Y shift in pixels')\n",
    "        target_header['SHIFT_X'] = (float(shift[1]), 'X shift in pixels')\n",
    "        \n",
    "        # Save aligned image\n",
    "        output_filename = Path(target_path).name.replace('normalized', 'aligned')\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        fits.writeto(output_path, aligned_data, target_header, overwrite=True)\n",
    "        print(f\"  Saved: {output_path}\")\n",
    "        print()\n",
    "\n",
    "def main():\n",
    "    # Define paths\n",
    "    input_dir = \"/home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/normalized\"\n",
    "    output_dir = \"/home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/second_alignment_v1\"\n",
    "    \n",
    "    # Define filters\n",
    "    filters = ['clear', 'g', 'r', 'i']\n",
    "    reference_filter = 'r'\n",
    "    \n",
    "    # Construct file paths\n",
    "    file_paths = {}\n",
    "    for filt in filters:\n",
    "        filename = f\"normalized_NGC1365_{filt}_stacked_sigma3.0.fits\"\n",
    "        file_paths[filt] = os.path.join(input_dir, filename)\n",
    "    \n",
    "    # Verify all files exist\n",
    "    print(\"Checking input files...\")\n",
    "    for filt, path in file_paths.items():\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"ERROR: File not found: {path}\")\n",
    "            return\n",
    "        else:\n",
    "            print(f\"  Found: {filt} - {path}\")\n",
    "    print()\n",
    "    \n",
    "    # Reference image\n",
    "    reference_path = file_paths[reference_filter]\n",
    "    \n",
    "    # Target images (all except reference)\n",
    "    target_paths = [file_paths[filt] for filt in filters if filt != reference_filter]\n",
    "    \n",
    "    # Perform alignment\n",
    "    print(\"=\"*70)\n",
    "    print(\"Starting alignment process...\")\n",
    "    print(f\"Reference filter: {reference_filter}\")\n",
    "    print(\"=\"*70)\n",
    "    print()\n",
    "    \n",
    "    align_images(reference_path, target_paths, output_dir)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"Alignment complete!\")\n",
    "    print(f\"Aligned images saved to: {output_dir}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d16b487a-15b6-466b-bddc-073ad3475f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTI-STRETCH ALIGNMENT - NGC1365\n",
      "================================================================================\n",
      "\n",
      "Input: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED\n",
      "Output: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/aligned\n",
      "Reference: r\n",
      "Methods: 6\n",
      "Filters: ['clear', 'g', 'i']\n",
      "\n",
      "================================================================================\n",
      "PROCESSING: NORMALIZED\n",
      "================================================================================\n",
      "\n",
      "  Loading reference: r\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Saved: aligned_normalized_NGC1365_r.fits\n",
      "\n",
      "  Processing: clear\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=15.397, dx=-0.157, total=15.398 px\n",
      "    Correlation: 0.836961\n",
      "    Time: 0.40s\n",
      "    Saved: aligned_normalized_NGC1365_clear.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: g\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=-2.922, dx=-15.936, total=16.202 px\n",
      "    Correlation: 0.680025\n",
      "    Time: 0.41s\n",
      "    Saved: aligned_normalized_NGC1365_g.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: i\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=16.343, dx=15.637, total=22.618 px\n",
      "    Correlation: 0.466603\n",
      "    Time: 0.41s\n",
      "    Saved: aligned_normalized_NGC1365_i.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "================================================================================\n",
      "PROCESSING: LOG\n",
      "================================================================================\n",
      "\n",
      "  Loading reference: r\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Saved: aligned_log_NGC1365_r.fits\n",
      "\n",
      "  Processing: clear\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=15.470, dx=-0.146, total=15.470 px\n",
      "    Correlation: 0.674135\n",
      "    Time: 0.41s\n",
      "    Saved: aligned_log_NGC1365_clear.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: g\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=-2.257, dx=-15.833, total=15.993 px\n",
      "    Correlation: 0.737873\n",
      "    Time: 0.42s\n",
      "    Saved: aligned_log_NGC1365_g.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: i\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=16.401, dx=15.021, total=22.240 px\n",
      "    Correlation: 0.489523\n",
      "    Time: 0.41s\n",
      "    Saved: aligned_log_NGC1365_i.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "================================================================================\n",
      "PROCESSING: HYPERBOLIC\n",
      "================================================================================\n",
      "\n",
      "  Loading reference: r\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Saved: aligned_hyperbolic_NGC1365_r.fits\n",
      "\n",
      "  Processing: clear\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=15.528, dx=-0.157, total=15.529 px\n",
      "    Correlation: 0.930513\n",
      "    Time: 0.41s\n",
      "    Saved: aligned_hyperbolic_NGC1365_clear.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: g\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=-2.274, dx=-15.877, total=16.039 px\n",
      "    Correlation: 0.919614\n",
      "    Time: 0.40s\n",
      "    Saved: aligned_hyperbolic_NGC1365_g.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: i\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=16.407, dx=15.059, total=22.271 px\n",
      "    Correlation: 0.822177\n",
      "    Time: 0.40s\n",
      "    Saved: aligned_hyperbolic_NGC1365_i.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "================================================================================\n",
      "PROCESSING: ASINH\n",
      "================================================================================\n",
      "\n",
      "  Loading reference: r\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Saved: aligned_asinh_NGC1365_r.fits\n",
      "\n",
      "  Processing: clear\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=15.500, dx=-0.150, total=15.501 px\n",
      "    Correlation: 0.883771\n",
      "    Time: 0.40s\n",
      "    Saved: aligned_asinh_NGC1365_clear.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: g\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=-2.272, dx=-15.856, total=16.018 px\n",
      "    Correlation: 0.881476\n",
      "    Time: 0.41s\n",
      "    Saved: aligned_asinh_NGC1365_g.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: i\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=16.407, dx=15.046, total=22.262 px\n",
      "    Correlation: 0.725489\n",
      "    Time: 0.39s\n",
      "    Saved: aligned_asinh_NGC1365_i.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "================================================================================\n",
      "PROCESSING: GAMMA\n",
      "================================================================================\n",
      "\n",
      "  Loading reference: r\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Saved: aligned_gamma_NGC1365_r.fits\n",
      "\n",
      "  Processing: clear\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=15.519, dx=-0.148, total=15.519 px\n",
      "    Correlation: 0.791158\n",
      "    Time: 0.40s\n",
      "    Saved: aligned_gamma_NGC1365_clear.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: g\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=-2.259, dx=-15.848, total=16.008 px\n",
      "    Correlation: 0.823631\n",
      "    Time: 0.42s\n",
      "    Saved: aligned_gamma_NGC1365_g.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: i\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=16.405, dx=15.080, total=22.283 px\n",
      "    Correlation: 0.625905\n",
      "    Time: 0.41s\n",
      "    Saved: aligned_gamma_NGC1365_i.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "================================================================================\n",
      "PROCESSING: ADAPTIVE_ASINH\n",
      "================================================================================\n",
      "\n",
      "  Loading reference: r\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Saved: aligned_adaptive_asinh_NGC1365_r.fits\n",
      "\n",
      "  Processing: clear\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=15.462, dx=-0.144, total=15.462 px\n",
      "    Correlation: 0.631700\n",
      "    Time: 0.41s\n",
      "    Saved: aligned_adaptive_asinh_NGC1365_clear.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: g\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=-2.252, dx=-15.826, total=15.985 px\n",
      "    Correlation: 0.706329\n",
      "    Time: 0.42s\n",
      "    Saved: aligned_adaptive_asinh_NGC1365_g.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "  Processing: i\n",
      "    Shape: (2048, 2048), Range: [0.0000, 1.0000]\n",
      "    Aligning...\n",
      "    Shift: dy=16.399, dx=15.014, total=22.234 px\n",
      "    Correlation: 0.453808\n",
      "    Time: 0.39s\n",
      "    Saved: aligned_adaptive_asinh_NGC1365_i.fits\n",
      "    Creating diagnostic...\n",
      "    ✓ Complete\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "NORMALIZED:\n",
      "  Reference: r\n",
      "\n",
      "  Filter    Shift-Y   Shift-X   Total     Correlation\n",
      "  ------------------------------------------------------------\n",
      "  clear      15.397    -0.157    15.398  0.836961\n",
      "  g          -2.922   -15.936    16.202  0.680025\n",
      "  i          16.343    15.637    22.618  0.466603\n",
      "\n",
      "LOG:\n",
      "  Reference: r\n",
      "\n",
      "  Filter    Shift-Y   Shift-X   Total     Correlation\n",
      "  ------------------------------------------------------------\n",
      "  clear      15.470    -0.146    15.470  0.674135\n",
      "  g          -2.257   -15.833    15.993  0.737873\n",
      "  i          16.401    15.021    22.240  0.489523\n",
      "\n",
      "HYPERBOLIC:\n",
      "  Reference: r\n",
      "\n",
      "  Filter    Shift-Y   Shift-X   Total     Correlation\n",
      "  ------------------------------------------------------------\n",
      "  clear      15.528    -0.157    15.529  0.930513\n",
      "  g          -2.274   -15.877    16.039  0.919614\n",
      "  i          16.407    15.059    22.271  0.822177\n",
      "\n",
      "ASINH:\n",
      "  Reference: r\n",
      "\n",
      "  Filter    Shift-Y   Shift-X   Total     Correlation\n",
      "  ------------------------------------------------------------\n",
      "  clear      15.500    -0.150    15.501  0.883771\n",
      "  g          -2.272   -15.856    16.018  0.881476\n",
      "  i          16.407    15.046    22.262  0.725489\n",
      "\n",
      "GAMMA:\n",
      "  Reference: r\n",
      "\n",
      "  Filter    Shift-Y   Shift-X   Total     Correlation\n",
      "  ------------------------------------------------------------\n",
      "  clear      15.519    -0.148    15.519  0.791158\n",
      "  g          -2.259   -15.848    16.008  0.823631\n",
      "  i          16.405    15.080    22.283  0.625905\n",
      "\n",
      "ADAPTIVE_ASINH:\n",
      "  Reference: r\n",
      "\n",
      "  Filter    Shift-Y   Shift-X   Total     Correlation\n",
      "  ------------------------------------------------------------\n",
      "  clear      15.462    -0.144    15.462  0.631700\n",
      "  g          -2.252   -15.826    15.985  0.706329\n",
      "  i          16.399    15.014    22.234  0.453808\n",
      "\n",
      "================================================================================\n",
      "✓ COMPLETE in 1.0 minutes\n",
      "================================================================================\n",
      "\n",
      "Outputs in: /home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/aligned/\n",
      "\n",
      "Next: Review diagnostic plots and proceed with color combination\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from scipy.ndimage import shift\n",
    "from scipy.fft import fft2, ifft2, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "BASE_PATH = \"/home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED\"\n",
    "OUTPUT_PATH = \"/home/devika/PhD/S2/Obs_Astronomy/Image_Processing/Ckoirama_2025-12-19/Image_reduction_workspace/STACKED/aligned\"\n",
    "\n",
    "# Filters and object\n",
    "FILTERS = ['clear', 'g', 'r', 'i']\n",
    "OBJECT_NAME = \"NGC1365\"\n",
    "REFERENCE_FILTER = 'r'\n",
    "\n",
    "# All stretch methods to align\n",
    "STRETCH_METHODS = [\n",
    "    'normalized',\n",
    "    'log',\n",
    "    'hyperbolic',\n",
    "    'asinh',\n",
    "    'gamma',\n",
    "    'adaptive_asinh'\n",
    "]\n",
    "\n",
    "# Cross-correlation parameters (optimized for speed)\n",
    "CORRELATION_PARAMS = {\n",
    "    'subsample': 4,\n",
    "    'edge_crop': 100,\n",
    "    'use_central_region': True,\n",
    "    'central_size': 800,\n",
    "}\n",
    "\n",
    "# Use parabolic refinement (much faster than optimize)\n",
    "USE_SUBPIXEL_REFINEMENT = True\n",
    "\n",
    "\n",
    "def load_stretched_image(filter_name, method):\n",
    "    \"\"\"Load stretched FITS image\"\"\"\n",
    "    if method == 'normalized':\n",
    "        subdir = 'normalized'\n",
    "        filename = f\"normalized_{OBJECT_NAME}_{filter_name}_stacked_sigma3.0.fits\"\n",
    "    else:\n",
    "        subdir = 'stretched'\n",
    "        filename = f\"stretched_{method}_{OBJECT_NAME}_{filter_name}.fits\"\n",
    "    \n",
    "    filepath = Path(BASE_PATH) / subdir / filename\n",
    "    \n",
    "    if not filepath.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "    \n",
    "    with fits.open(filepath) as hdul:\n",
    "        data = hdul[0].data.astype(np.float64)\n",
    "        header = hdul[0].header\n",
    "    \n",
    "    return data, header\n",
    "\n",
    "\n",
    "def prepare_for_correlation(image, subsample=1, edge_crop=50, \n",
    "                           use_central=False, central_size=1024):\n",
    "    \"\"\"Prepare image for cross-correlation\"\"\"\n",
    "    image = np.nan_to_num(image, nan=0.0)\n",
    "    \n",
    "    if edge_crop > 0:\n",
    "        image = image[edge_crop:-edge_crop, edge_crop:-edge_crop]\n",
    "    \n",
    "    if use_central and image.shape[0] > central_size:\n",
    "        cy, cx = image.shape[0] // 2, image.shape[1] // 2\n",
    "        half_size = central_size // 2\n",
    "        image = image[cy-half_size:cy+half_size, cx-half_size:cx+half_size]\n",
    "    \n",
    "    if subsample > 1:\n",
    "        image = image[::subsample, ::subsample]\n",
    "    \n",
    "    # Normalize\n",
    "    image = image - np.mean(image)\n",
    "    std = np.std(image)\n",
    "    if std > 0:\n",
    "        image = image / std\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def cross_correlate_images(ref_image, target_image):\n",
    "    \"\"\"\n",
    "    Compute cross-correlation using FFT (very fast)\n",
    "    \"\"\"\n",
    "    # Pad to avoid edge effects\n",
    "    pad_y = ref_image.shape[0] // 4\n",
    "    pad_x = ref_image.shape[1] // 4\n",
    "    \n",
    "    ref_padded = np.pad(ref_image, ((pad_y, pad_y), (pad_x, pad_x)), mode='constant')\n",
    "    target_padded = np.pad(target_image, ((pad_y, pad_y), (pad_x, pad_x)), mode='constant')\n",
    "    \n",
    "    # FFT correlation\n",
    "    ref_fft = fft2(ref_padded)\n",
    "    target_fft = fft2(target_padded)\n",
    "    correlation = fftshift(ifft2(ref_fft * np.conj(target_fft)).real)\n",
    "    \n",
    "    # Find peak\n",
    "    peak_pos = np.unravel_index(np.argmax(correlation), correlation.shape)\n",
    "    center_y, center_x = np.array(correlation.shape) // 2\n",
    "    dy = peak_pos[0] - center_y\n",
    "    dx = peak_pos[1] - center_x\n",
    "    \n",
    "    return dy, dx, correlation\n",
    "\n",
    "\n",
    "def refine_shift_parabolic(correlation, dy, dx):\n",
    "    \"\"\"\n",
    "    Refine shift to sub-pixel accuracy using parabolic fit\n",
    "    \"\"\"\n",
    "    ny, nx = correlation.shape\n",
    "    center_y, center_x = ny // 2, nx // 2\n",
    "    peak_y = center_y + dy\n",
    "    peak_x = center_x + dx\n",
    "    \n",
    "    # Check bounds\n",
    "    if peak_y <= 0 or peak_y >= ny-1 or peak_x <= 0 or peak_x >= nx-1:\n",
    "        return dy, dx\n",
    "    \n",
    "    # Parabolic fit in X\n",
    "    x_vals = correlation[peak_y, peak_x-1:peak_x+2]\n",
    "    if len(x_vals) == 3:\n",
    "        denom = x_vals[0] - 2*x_vals[1] + x_vals[2]\n",
    "        if abs(denom) > 1e-10:\n",
    "            dx_sub = 0.5 * (x_vals[0] - x_vals[2]) / denom\n",
    "            dx = dx + dx_sub\n",
    "    \n",
    "    # Parabolic fit in Y\n",
    "    y_vals = correlation[peak_y-1:peak_y+2, peak_x]\n",
    "    if len(y_vals) == 3:\n",
    "        denom = y_vals[0] - 2*y_vals[1] + y_vals[2]\n",
    "        if abs(denom) > 1e-10:\n",
    "            dy_sub = 0.5 * (y_vals[0] - y_vals[2]) / denom\n",
    "            dy = dy + dy_sub\n",
    "    \n",
    "    return dy, dx\n",
    "\n",
    "\n",
    "def apply_shift(image, dy, dx, subsample=1):\n",
    "    \"\"\"Apply shift to full resolution image\"\"\"\n",
    "    full_dy = dy * subsample\n",
    "    full_dx = dx * subsample\n",
    "    shifted = shift(image, [full_dy, full_dx], order=3, mode='constant', cval=0)\n",
    "    return shifted, full_dy, full_dx\n",
    "\n",
    "\n",
    "def align_filter(ref_data, target_data):\n",
    "    \"\"\"Align target to reference using cross-correlation\"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Prepare images\n",
    "    ref_prep = prepare_for_correlation(\n",
    "        ref_data,\n",
    "        subsample=CORRELATION_PARAMS['subsample'],\n",
    "        edge_crop=CORRELATION_PARAMS['edge_crop'],\n",
    "        use_central=CORRELATION_PARAMS['use_central_region'],\n",
    "        central_size=CORRELATION_PARAMS['central_size']\n",
    "    )\n",
    "    \n",
    "    target_prep = prepare_for_correlation(\n",
    "        target_data,\n",
    "        subsample=CORRELATION_PARAMS['subsample'],\n",
    "        edge_crop=CORRELATION_PARAMS['edge_crop'],\n",
    "        use_central=CORRELATION_PARAMS['use_central_region'],\n",
    "        central_size=CORRELATION_PARAMS['central_size']\n",
    "    )\n",
    "    \n",
    "    # Cross-correlate\n",
    "    dy, dx, correlation = cross_correlate_images(ref_prep, target_prep)\n",
    "    \n",
    "    # Sub-pixel refinement\n",
    "    if USE_SUBPIXEL_REFINEMENT:\n",
    "        dy, dx = refine_shift_parabolic(correlation, dy, dx)\n",
    "    \n",
    "    # Apply shift\n",
    "    aligned, full_dy, full_dx = apply_shift(\n",
    "        target_data, dy, dx,\n",
    "        subsample=CORRELATION_PARAMS['subsample']\n",
    "    )\n",
    "    \n",
    "    # Calculate correlation coefficient\n",
    "    ref_norm = (ref_data - np.mean(ref_data)) / (np.std(ref_data) + 1e-10)\n",
    "    aligned_norm = (aligned - np.mean(aligned)) / (np.std(aligned) + 1e-10)\n",
    "    corr = np.sum(ref_norm * aligned_norm) / ref_norm.size\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    return aligned, full_dy, full_dx, corr, elapsed\n",
    "\n",
    "\n",
    "def create_diagnostic(ref_data, original_data, aligned_data, \n",
    "                     filter_name, method, dy, dx, corr, output_path):\n",
    "    \"\"\"Create diagnostic plots\"\"\"\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    gs = fig.add_gridspec(2, 4, hspace=0.25, wspace=0.3)\n",
    "    \n",
    "    # Determine display range\n",
    "    if method in ['normalized', 'log', 'gamma']:\n",
    "        vmin, vmax = 0, 1\n",
    "    else:\n",
    "        vmin, vmax = 0, 0.8\n",
    "    \n",
    "    # Row 1: Full images\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(ref_data, cmap='gray', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title(f'Reference ({REFERENCE_FILTER})', fontsize=11, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(original_data, cmap='gray', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax2.set_title(f'Original ({filter_name})', fontsize=11, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(aligned_data, cmap='gray', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax3.set_title(f'Aligned ({filter_name})', fontsize=11, fontweight='bold')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    diff = ref_data - aligned_data\n",
    "    vmax_diff = np.percentile(np.abs(diff), 98)\n",
    "    ax4.imshow(diff, cmap='RdBu_r', origin='lower', vmin=-vmax_diff, vmax=vmax_diff)\n",
    "    ax4.set_title('Difference', fontsize=11, fontweight='bold')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Row 2: Zoomed views\n",
    "    cy, cx = ref_data.shape[0] // 2, ref_data.shape[1] // 2\n",
    "    zoom = 400\n",
    "    \n",
    "    ax5 = fig.add_subplot(gs[1, 0])\n",
    "    ax5.imshow(ref_data[cy-zoom:cy+zoom, cx-zoom:cx+zoom],\n",
    "               cmap='gray', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax5.set_title('Reference (zoom)', fontsize=11)\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    ax6 = fig.add_subplot(gs[1, 1])\n",
    "    ax6.imshow(original_data[cy-zoom:cy+zoom, cx-zoom:cx+zoom],\n",
    "               cmap='gray', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax6.set_title('Original (zoom)', fontsize=11)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    ax7 = fig.add_subplot(gs[1, 2])\n",
    "    ax7.imshow(aligned_data[cy-zoom:cy+zoom, cx-zoom:cx+zoom],\n",
    "               cmap='gray', origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax7.set_title('Aligned (zoom)', fontsize=11)\n",
    "    ax7.axis('off')\n",
    "    \n",
    "    # Statistics\n",
    "    ax8 = fig.add_subplot(gs[1, 3])\n",
    "    ax8.axis('off')\n",
    "    \n",
    "    total = np.sqrt(dy**2 + dx**2)\n",
    "    status = '✓ EXCELLENT' if corr > 0.95 else '✓ GOOD' if corr > 0.90 else '⚠ CHECK'\n",
    "    \n",
    "    stats = f\"\"\"\n",
    "ALIGNMENT STATISTICS\n",
    "{'='*35}\n",
    "\n",
    "Method: {method}\n",
    "Filter: {filter_name} → {REFERENCE_FILTER}\n",
    "\n",
    "Shift Applied:\n",
    "  dy = {dy:.3f} px\n",
    "  dx = {dx:.3f} px\n",
    "  Total = {total:.3f} px\n",
    "\n",
    "Correlation: {corr:.6f}\n",
    "\n",
    "Status: {status}\n",
    "    \"\"\"\n",
    "    \n",
    "    ax8.text(0.1, 0.95, stats, transform=ax8.transAxes,\n",
    "             fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.suptitle(f'{OBJECT_NAME} - {method.upper()} - {filter_name} → {REFERENCE_FILTER}',\n",
    "                fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Save\n",
    "    outfile = Path(output_path) / f\"alignment_{method}_{OBJECT_NAME}_{filter_name}.png\"\n",
    "    plt.savefig(outfile, dpi=120, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def process_method(method):\n",
    "    \"\"\"Process all filters for one stretch method\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESSING: {method.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    method_dir = Path(OUTPUT_PATH) / method\n",
    "    method_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load reference\n",
    "    print(f\"\\n  Loading reference: {REFERENCE_FILTER}\")\n",
    "    try:\n",
    "        ref_data, ref_header = load_stretched_image(REFERENCE_FILTER, method)\n",
    "        print(f\"    Shape: {ref_data.shape}, Range: [{np.nanmin(ref_data):.4f}, {np.nanmax(ref_data):.4f}]\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"    ✗ {e}\")\n",
    "        return {}\n",
    "    \n",
    "    # Save reference\n",
    "    ref_file = method_dir / f\"aligned_{method}_{OBJECT_NAME}_{REFERENCE_FILTER}.fits\"\n",
    "    ref_header['ALIGNED'] = 'REFERENCE'\n",
    "    ref_header['ALIGNMET'] = 'CROSS-CORRELATION'\n",
    "    ref_header['STRETCH'] = method\n",
    "    fits.writeto(ref_file, ref_data.astype(np.float32), ref_header, overwrite=True)\n",
    "    print(f\"    Saved: {ref_file.name}\")\n",
    "    \n",
    "    # Align other filters\n",
    "    results = {}\n",
    "    \n",
    "    for filt in FILTERS:\n",
    "        if filt == REFERENCE_FILTER:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n  Processing: {filt}\")\n",
    "        \n",
    "        try:\n",
    "            target_data, target_header = load_stretched_image(filt, method)\n",
    "            print(f\"    Shape: {target_data.shape}, Range: [{np.nanmin(target_data):.4f}, {np.nanmax(target_data):.4f}]\")\n",
    "            \n",
    "            original = target_data.copy()\n",
    "            \n",
    "            # Align\n",
    "            print(f\"    Aligning...\")\n",
    "            aligned, dy, dx, corr, elapsed = align_filter(ref_data, target_data)\n",
    "            \n",
    "            total = np.sqrt(dy**2 + dx**2)\n",
    "            print(f\"    Shift: dy={dy:.3f}, dx={dx:.3f}, total={total:.3f} px\")\n",
    "            print(f\"    Correlation: {corr:.6f}\")\n",
    "            print(f\"    Time: {elapsed:.2f}s\")\n",
    "            \n",
    "            # Save\n",
    "            out_file = method_dir / f\"aligned_{method}_{OBJECT_NAME}_{filt}.fits\"\n",
    "            target_header['ALIGNED'] = 'YES'\n",
    "            target_header['ALIGNMET'] = 'CROSS-CORRELATION'\n",
    "            target_header['ALIGNREF'] = REFERENCE_FILTER\n",
    "            target_header['STRETCH'] = method\n",
    "            target_header['SHIFTDY'] = (dy, 'Y shift (pixels)')\n",
    "            target_header['SHIFTDX'] = (dx, 'X shift (pixels)')\n",
    "            target_header['SHIFTTOT'] = (total, 'Total shift (pixels)')\n",
    "            target_header['CORR'] = (corr, 'Correlation coefficient')\n",
    "            \n",
    "            fits.writeto(out_file, aligned.astype(np.float32), target_header, overwrite=True)\n",
    "            print(f\"    Saved: {out_file.name}\")\n",
    "            \n",
    "            # Diagnostic\n",
    "            print(f\"    Creating diagnostic...\")\n",
    "            create_diagnostic(ref_data, original, aligned, filt, method, dy, dx, corr, method_dir)\n",
    "            \n",
    "            results[filt] = {'dy': dy, 'dx': dx, 'total': total, 'corr': corr}\n",
    "            print(f\"    ✓ Complete\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"MULTI-STRETCH ALIGNMENT - {OBJECT_NAME}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nInput: {BASE_PATH}\")\n",
    "    print(f\"Output: {OUTPUT_PATH}\")\n",
    "    print(f\"Reference: {REFERENCE_FILTER}\")\n",
    "    print(f\"Methods: {len(STRETCH_METHODS)}\")\n",
    "    print(f\"Filters: {[f for f in FILTERS if f != REFERENCE_FILTER]}\")\n",
    "    \n",
    "    Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    all_results = {}\n",
    "    total_start = time.time()\n",
    "    \n",
    "    for method in STRETCH_METHODS:\n",
    "        results = process_method(method)\n",
    "        if results:\n",
    "            all_results[method] = results\n",
    "    \n",
    "    total_elapsed = time.time() - total_start\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for method in STRETCH_METHODS:\n",
    "        if method not in all_results:\n",
    "            print(f\"\\n{method.upper()}: No results\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{method.upper()}:\")\n",
    "        print(f\"  Reference: {REFERENCE_FILTER}\")\n",
    "        print(f\"\\n  Filter    Shift-Y   Shift-X   Total     Correlation\")\n",
    "        print(\"  \" + \"-\"*60)\n",
    "        \n",
    "        for filt, res in all_results[method].items():\n",
    "            print(f\"  {filt:8s} {res['dy']:8.3f}  {res['dx']:8.3f}  \"\n",
    "                  f\"{res['total']:8.3f}  {res['corr']:8.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✓ COMPLETE in {total_elapsed/60:.1f} minutes\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nOutputs in: {OUTPUT_PATH}/\")\n",
    "    print(\"\\nNext: Review diagnostic plots and proceed with color combination\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16302de-7caf-457b-b820-7d500696bfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
